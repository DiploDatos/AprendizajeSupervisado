{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algunas buenas prácticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar/usar una base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos base de datos [Titanic](https://www.kaggle.com/c/titanic/data)\n",
    "\n",
    "La base de datos que utilizarán cuenta con 9 variables independientes y una variable respuesta. Las variables son:\n",
    "\n",
    "- *survival* : 0 si no sobrevivió, 1 si sobrevivió (variable respuesta).\n",
    "\n",
    "- *pclass*: clase del ticket. 1 = primera clase, 2 = segunda clase, 3 = tercera clase.\n",
    "\n",
    "- *sex*: Sexo del pasajero. Male = Masculino, Female = Femenino.\n",
    "\n",
    "- *Age*: Edad en años del pasajero. \n",
    "\n",
    "- *sibsp*: Número de familiares (hermanos, pareja) en el Titanic\n",
    "\n",
    "- *parch*: Número de padres o hijos en el Titanic.\n",
    "\n",
    "- *ticket*: Número de ticket.\n",
    "\n",
    "- *fare*: El costo del pasaje.\n",
    "\n",
    "- *cabin*: El número de cabina.\n",
    "\n",
    "- *Embarked*: Puerto donde embarcó. C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('demo_12_dataset/train.csv')\n",
    "test_data = pd.read_csv('demo_12_dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio de la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer gráficos exploratorios para entender la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x=train_data['Sex'],hue=train_data['Survived'],palette=('red','green'))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x=train_data['Pclass'],hue=train_data['Survived'],palette=('red','green'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "var = 'Pclass'\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Died')\n",
    "plt.pie(train_data.groupby('Survived')[var].value_counts()[0],\n",
    "        labels=train_data.groupby('Survived')[var].value_counts()[0].index,\n",
    "        autopct='%1.1f%%', colors=['green','blue','red'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Survived')\n",
    "plt.pie(train_data.groupby('Survived')[var].value_counts()[1],\n",
    "        labels=train_data.groupby('Survived')[var].value_counts()[1].index,\n",
    "        autopct='%1.1f%%', colors=['red','green','blue'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer tablas para entender un poco más.\n",
    "\n",
    "Calculemos el valor medio de la variable supervivencia en función de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos la supervivencia en función del sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O en función de la edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_data, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de variables o features\n",
    "\n",
    "Podemos tirar las variables PassengerId y Ticket. Cabin está muy incompleta así que la podemos tirar también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PassengerID_val = test_data.PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_vars = ['PassengerId', 'Ticket', 'Cabin']\n",
    "\n",
    "train_data = train_data.drop(drop_vars, axis=1)\n",
    "test_data = test_data.drop(drop_vars, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qué información hay en la variable Name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in (train_data, test_data):\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(train_data['Title'], train_data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in (train_data, test_data):\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "train_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in (train_data, test_data):\n",
    "    dataset.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputación de datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Documentación](https://scikit-learn.org/stable/modules/impute.html) de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in (train_data, test_data):\n",
    "    dataset['Embarked'] = pd.Series(list(SimpleImputer(strategy=\"constant\", fill_value=\"S\").fit_transform(np.array(dataset['Embarked']).reshape(-1, 1))))\n",
    "    dataset['Age'] = SimpleImputer(strategy=\"median\").fit_transform(np.array(dataset['Age']).reshape(-1, 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variables categóricas deber transformarse a numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Te = LabelEncoder()\n",
    "for dataset in (train_data, test_data):\n",
    "    dataset['Title'] = Te.fit_transform(dataset['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Te.inverse_transform([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = LabelEncoder()\n",
    "for dataset in (train_data, test_data):\n",
    "    dataset['Sex'] = se.fit_transform(dataset['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eenc = LabelEncoder()\n",
    "for dataset in (train_data, test_data):\n",
    "    dataset['Embarked'] = Eenc.fit_transform(list(dataset['Embarked']))\n",
    "Eenc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bandas para Age y Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in (train_data, test_data):\n",
    "    dataset['AgeBand'] = pd.cut(dataset['Age'], 5)\n",
    "    dataset.drop('Age', axis=1, inplace=True)\n",
    "train_data[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aenc = LabelEncoder()\n",
    "for dataset in (train_data, test_data):\n",
    "    dataset['AgeBand'] = Aenc.fit_transform(dataset['AgeBand'])\n",
    "Aenc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in (train_data, test_data):\n",
    "    dataset['FareBand'] = pd.cut(dataset['Fare'], 4)\n",
    "    dataset.drop('Fare', axis=1, inplace=True)\n",
    "train_data[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fenc = LabelEncoder()\n",
    "for dataset in (train_data, test_data):\n",
    "    dataset['FareBand'] = Fenc.fit_transform(dataset['FareBand'])\n",
    "Fenc.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train Dataset: Used to fit the machine learning model.\n",
    "\n",
    "- Test Dataset: Used to evaluate the fit machine learning model.\n",
    "\n",
    "- Stratified* Importante chequear en datos desbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('Survived',axis=1)\n",
    "y = train_data.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Documentación](https://scikit-learn.org/stable/model_selection.html) de sklearn acerca de selección de modelo.\n",
    "\n",
    "- [Documentación](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) de sklear acerca de métricas de bondad de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold, StratifiedKFold, LeaveOneOut, LeavePOut\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, roc_auc_score, mean_squared_error, r2_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "clfs =  [DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        LogisticRegression(),\n",
    "        MLPClassifier(),\n",
    "        XGBClassifier(),\n",
    "        GaussianNB(),\n",
    "        LinearSVC()]\n",
    "\n",
    "names = ['Arbol de decisión',\n",
    "        'Random Forest',\n",
    "        'Regresión Logística',\n",
    "        'Perceptrón multicapa',\n",
    "        'XGBoost',\n",
    "        'Naive Bayes',\n",
    "        'SVM']\n",
    "\n",
    "trained_models = []\n",
    "accuracy_models = []\n",
    "for clf, name in zip(clfs, names):\n",
    "    print(name)\n",
    "    clf.fit(x_train, y_train)\n",
    "    train_predictions = clf.predict(x_train)\n",
    "    accuracy = accuracy_score(y_train, train_predictions)\n",
    "    print(f\"Accuracy train {name}: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "    test_predictions = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, test_predictions)\n",
    "    print(f\"Accuracy test {name}: %.2f%%\" % (accuracy * 100.0))\n",
    "    trained_models.append(clf)    \n",
    "    accuracy_models.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({'Model':names, 'Score':accuracy_models})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_grid = {'hidden_layer_sizes':(100, (10,10)),\n",
    "                'activation': ('relu','tanh'),\n",
    "                'solver': ('sgd', 'adam'),\n",
    "                'alpha': np.logspace(-5,-2,3),\n",
    "                'learning_rate': ('constant', 'adaptive')}\n",
    "\n",
    "grid = GridSearchCV(MLPClassifier(max_iter=300), parameter_grid)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparación con RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid2 = {'n_estimators':(10,100,200),\n",
    "                'criterion': ('gini', 'entropy', 'log_loss'),\n",
    "                'max_depth': (None, 10, 20),\n",
    "                'max_features': ('sqrt', 'log2')}\n",
    "\n",
    "grid2 = GridSearchCV(RandomForestClassifier(n_jobs=2), parameter_grid2)\n",
    "grid2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS=5\n",
    "cv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=10)\n",
    "\n",
    "\n",
    "for clfi in [MLPClassifier(**grid.best_params_, max_iter=300), RandomForestClassifier(**grid2.best_params_, n_jobs=2)]:\n",
    "    print(clfi)\n",
    "    avg_accuracy = 0\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(x_train, y_train)):\n",
    "        xi, yi = np.array(x_train)[train_idx], np.array(y_train)[train_idx]\n",
    "        x_valid, y_valid = np.array(x_train)[val_idx], np.array(y_train)[val_idx]\n",
    "        clfi = clfi.fit(xi, yi)\n",
    "\n",
    "        test_predictions = clfi.predict(x_valid)\n",
    "        accuracy = accuracy_score(y_valid, test_predictions)\n",
    "        avg_accuracy +=accuracy\n",
    "        print(f\"accuracy test fold {fold}: {accuracy * 100.0 :.2f}\" % ())\n",
    "    avg_accuracy /= FOLDS\n",
    "    print(f'Avg. accuracy = {avg_accuracy * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de modelo final y análisis de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(**grid.best_params_, max_iter=400)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "test_predictions = clf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, test_predictions)\n",
    "accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_curve\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, test_predictions, display_labels=(1,0))\n",
    "plt.show()\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,clf.predict_proba(x_test)[:,1])\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlim([-0.02, 1])\n",
    "plt.ylim([0, 1.02])\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerID_val,\n",
    "        \"Survived\": clf.predict(test_data)\n",
    "    })\n",
    "#submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo basado en este [link](https://www.kaggle.com/code/startupsci/titanic-data-science-solutions)\n",
    "\n",
    "[Doc](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py) sobre curvas Receiver Operating Characteristic (ROC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b65fc4380ac725e50a330b268a227bbdbe91bddfffbf68e5f7ce9848a2b8d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
