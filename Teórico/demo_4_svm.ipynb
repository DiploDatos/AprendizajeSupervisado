{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.neural_network\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlutils\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_up_down(size, seed=39):\n",
    "    np.random.seed(seed)\n",
    "    x = np.random.poisson(5, size) * (np.random.randint(0,2, size) * 2 - 1)\n",
    "    y = (np.random.poisson(5, size) + 1) * (np.random.randint(0,2, size) * 2 - 1)\n",
    "    X = np.array(list(zip(x,y)))\n",
    "    Y = (X[:,1] > 0).astype(np.int8)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_dataset_up_down(100)\n",
    "ax = plt.axes()\n",
    "ax.set_aspect(\"equal\", adjustable=\"datalim\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap=plt.cm.Spectral)\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un clasificador basado en una máquina de soporte compacto ([Documentación](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$0 = \\mathbf{w^T x} + b = w_0 x_0 + w_1 x_1 + intercept \\rightarrow x_1 =  - \\frac{w_0}{w_1} x_0 - \\frac{intercept}{w_1}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.svm.LinearSVC()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "b = - clf.intercept_[0] / w[1]\n",
    "x_0 = np.linspace(min(X[:,0]) - 1, max(X[:,0]) + 1)\n",
    "x_1 = a * x_0 + b\n",
    "\n",
    "plt.plot(x_0, x_1, 'k-', label=\"non weighted div\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap=plt.cm.Spectral)\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "print ((\"x_1 = %.4f * x_0 + %.4f\") % (a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qué pasaría ahora con más datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_dataset_up_down(800)\n",
    "mlutils.plot_decision_boundary(lambda x: clf.predict(x), X.T, Y.T)\n",
    "predictions = clf.predict(X)\n",
    "print ('Accuracy: %d ' % ((np.sum(Y == predictions))/float(Y.size)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que pasa si tenemos una base de datos con algo de ruido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_dataset_up_down(800, 1)\n",
    "some_noise = np.random.binomial(1, .03, Y.shape[0])\n",
    "Y = np.logical_xor(Y, some_noise).astype(np.int8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.svm.LinearSVC()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "b = - clf.intercept_[0] / w[1]\n",
    "x_0 = np.linspace(min(X[:,0]) - 1, max(X[:,0]) + 1)\n",
    "x_1 = a * x_0 + b\n",
    "\n",
    "plt.plot(x_0, x_1, 'k-', label=\"non weighted div\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap=plt.cm.Spectral)\n",
    "plt.xlabel('$x_0$')\n",
    "plt.ylabel('$x_1$')\n",
    "print ((\"x_1 = %.4f * x_0 + %.4f\") % (a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con un conjunto de datos distinto y veamos como impacta la elección del parámetro C\n",
    "\n",
    "Estamos minimizando ([doc](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC))\n",
    "\n",
    "$\\lambda({C}) ||w||^2 + \\frac{1}{n}\\sum_{i=1}^n \\max(0, 1-y_i (\\mathbf{w^T x_i}-b))$\n",
    "\n",
    "En principio, grandes valores de C resultan en márgenes menores y pequeños valores de C resultan en márgenes más amplios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_blobs(n_samples=100, centers=2, random_state=3, cluster_std=2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=30, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.svm.LinearSVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "for i, C in enumerate([0.1, 100]):\n",
    "    # \"hinge\" is the standard SVM loss\n",
    "    clf = sklearn.svm.LinearSVC(C=C, loss=\"hinge\", random_state=26).fit(X, Y)\n",
    "    predictions = clf.predict(X)\n",
    "    print (C, '- Accuracy: %d ' % ((np.sum(Y == predictions))/float(Y.size)*100))\n",
    "    # obtain the support vectors through the decision function\n",
    "    decision_function = clf.decision_function(X)\n",
    "    # we can also calculate the decision function manually\n",
    "    # decision_function = np.dot(X, clf.coef_[0]) + clf.intercept_[0]\n",
    "    # The support vectors are the samples that lie within the margin\n",
    "    # boundaries, whose size is conventionally constrained to 1\n",
    "    support_vector_indices = np.where(np.abs(decision_function) <= 1 + 1e-15)[0]\n",
    "    support_vectors = X[support_vector_indices]\n",
    "\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, s=30, cmap=plt.cm.Spectral)\n",
    "    ax = plt.gca()\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X,\n",
    "        ax=ax,\n",
    "        grid_resolution=50,\n",
    "        plot_method=\"contour\",\n",
    "        colors=\"k\",\n",
    "        levels=[-1, 0, 1],\n",
    "        alpha=0.5,\n",
    "        linestyles=[\"--\", \"-\", \"--\"],\n",
    "    )\n",
    "    plt.scatter(\n",
    "        support_vectors[:, 0],\n",
    "        support_vectors[:, 1],\n",
    "        s=100,\n",
    "        linewidth=1,\n",
    "        facecolors=\"none\",\n",
    "        edgecolors=\"k\",\n",
    "    )\n",
    "    plt.title(\"C=\" + str(C))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias:\n",
    " * Scikit: [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html#support-vector-machines)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6b65fc4380ac725e50a330b268a227bbdbe91bddfffbf68e5f7ce9848a2b8d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
