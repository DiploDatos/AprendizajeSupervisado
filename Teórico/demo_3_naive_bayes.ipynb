{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_table(\"./demo_3_dataset/spam_or_ham.txt\", header=None, names=[\"target\", \"text\"])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham:\n",
      "Nah I don't think he goes to usf, he lives around here though\n",
      "spam:\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "print('ham:')\n",
    "print(dataset.iloc[4,1])\n",
    "print('spam:')\n",
    "print(dataset.iloc[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize\n",
    "\n",
    "Transform the input from text into a bag of words matrix ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorized_data= vectorizer.fit_transform(dataset[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['huge', 'hugging', 'hugh', 'hugs', 'huh', 'hui', 'huiming', 'hum',\n",
       "       'humanities', 'humans', 'hun', 'hundred', 'hundreds', 'hungover',\n",
       "       'hungry', 'hunks', 'hunny', 'hunt', 'hunting', 'hurricanes',\n",
       "       'hurried', 'hurry', 'hurt', 'hurting', 'hurts', 'husband',\n",
       "       'hussey', 'hustle', 'hut', 'hv', 'hv9d', 'hvae', 'hw', 'hyde',\n",
       "       'hype', 'hypertension', 'hypotheticalhuagauahahuagahyuhagga',\n",
       "       'iam', 'ias', 'ibh', 'ibhltd', 'ibiza', 'ibm', 'ibn', 'ibored',\n",
       "       'ibuprofens', 'ic', 'iccha', 'ice', 'icic', 'icicibank', 'icky',\n",
       "       'icmb3cktz8r7', 'icon', 'id', 'idc', 'idea', 'ideal', 'ideas',\n",
       "       'identification', 'identifier', 'idew', 'idiot', 'idk', 'idps',\n",
       "       'idu', 'ie', 'if', 'iff', 'ifink', 'ig11', 'ignorant', 'ignore',\n",
       "       'ignoring', 'ihave', 'ijust', 'ikea', 'ikno', 'iknow', 'il',\n",
       "       'ileave', 'ill', 'illness', 'illspeak', 'ilol', 'im', 'image',\n",
       "       'images', 'imagination', 'imagine', 'imat', 'imf', 'img', 'imin',\n",
       "       'imma', 'immed', 'immediately', 'immunisation', 'imp', 'impatient',\n",
       "       'impede', 'implications', 'important', 'importantly', 'imposed',\n",
       "       'impossible', 'imposter', 'impress', 'impressed', 'impression',\n",
       "       'impressively', 'improve', 'improved', 'imprtant', 'in', 'in2',\n",
       "       'inc', 'inch', 'inches', 'incident', 'inclu', 'include',\n",
       "       'includes', 'including', 'inclusive', 'incomm', 'inconsiderate',\n",
       "       'inconvenience', 'inconvenient', 'incorrect', 'increase',\n",
       "       'incredible', 'increments', 'inde', 'indeed', 'independence',\n",
       "       'independently', 'index', 'india', 'indian', 'indians', 'indicate',\n",
       "       'individual', 'indyarocks', 'inever', 'infact', 'infections',\n",
       "       'infernal', 'influx', 'info', 'inform', 'information', 'informed',\n",
       "       'infra', 'infront', 'ing', 'ingredients', 'initiate', 'ink',\n",
       "       'inlude', 'inmind', 'inner', 'innings', 'innocent', 'innu',\n",
       "       'inperialmusic', 'inpersonation', 'inr', 'insects', 'insha',\n",
       "       'inshah', 'inside', 'inspection', 'inst', 'install',\n",
       "       'installation', 'installing', 'instant', 'instantly', 'instead',\n",
       "       'instituitions', 'instructions', 'insurance', 'intelligent',\n",
       "       'intend', 'intention', 'intentions', 'interest', 'interested',\n",
       "       'interesting', 'interflora', 'interfued', 'internal', 'internet',\n",
       "       'interview', 'interviews', 'interviw', 'intha', 'into', 'intrepid'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[4000:4200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_data.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_data, dataset.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver algún caso en particular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busquemos una entrada spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2433     ham\n",
       "4950     ham\n",
       "3772     ham\n",
       "2304     ham\n",
       "2947     ham\n",
       "1813     ham\n",
       "1175     ham\n",
       "4032     ham\n",
       "2534     ham\n",
       "5210     ham\n",
       "5189    spam\n",
       "4003     ham\n",
       "3098     ham\n",
       "1682     ham\n",
       "4120     ham\n",
       "3643     ham\n",
       "161      ham\n",
       "2055     ham\n",
       "5386     ham\n",
       "2135     ham\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero comparemos si nuestro clasificador está prediciendo correctamente los datos del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2433    True\n",
       "4950    True\n",
       "3772    True\n",
       "2304    True\n",
       "2947    True\n",
       "1813    True\n",
       "1175    True\n",
       "4032    True\n",
       "2534    True\n",
       "5210    True\n",
       "5189    True\n",
       "4003    True\n",
       "3098    True\n",
       "1682    True\n",
       "4120    True\n",
       "3643    True\n",
       "161     True\n",
       "2055    True\n",
       "5386    True\n",
       "2135    True\n",
       "Name: target, dtype: bool"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20] == clf.predict(X_train)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener la probabilidad de que haya sido spam o ham:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0001, 0.    ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(clf.feature_log_prob_).round(4)[:,5189]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la probabilidad de spam es mayor que la de ham. Veamos lo mismo pero para un caso que no era spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.695e-05, 4.396e-05])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.exp(clf.feature_log_prob_).round(8)[:,2135]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso la probabilidad de ham es mayor que la de spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3625     True\n",
       "4199     True\n",
       "4080     True\n",
       "4136     True\n",
       "4062     True\n",
       "625      True\n",
       "2606     True\n",
       "264      True\n",
       "4769     True\n",
       "1090     True\n",
       "2759     True\n",
       "919      True\n",
       "3798     True\n",
       "1500     True\n",
       "5369     True\n",
       "3121     True\n",
       "2704     True\n",
       "4600    False\n",
       "3043     True\n",
       "3853     True\n",
       "Name: target, dtype: bool"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20] == clf.predict(X_test)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       968\n",
      "        spam       0.92      0.97      0.94       147\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.98      0.97      1115\n",
      "weighted avg       0.99      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label a negative sample as positive.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The F-beta score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "98b921049c439807c081d6616d9731da5920d3b6edca6190edeae5a80cc907f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
