{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(dataset.data, dataset.target, test_size=0.33, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_train)\n",
    "print(classification_report(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué sucede si probamos el modelo con los datos de Test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "Uno de los principales problemas de los árboles de decisión es el sobreajuste a los datos de entrenamiento. Suelen tener sesgo chico pero su varianza suele ser muy grande. La manera de sobrepasar este problema es utilizar el método de Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Random Forest en cierto sentido promedia múltiples árboles de decisión, entrenados con distintas partes del conjunto de datos de entrenamiento, con el objetivo de reducir la varianza.\n",
    "\n",
    "El problema de este método es que se pierde la interpretabilidad tan clara que tiene un árbol de decisión acerca de cómo el algoritmo toma la decisión de clasificación o regresión. Sin embargo, suele exponenciar la performance del modelo final.\n",
    "\n",
    "El método utiliza el concepto de \"Bagging\", que se traduce literal a \"embolsar\", pero que refiere a tomar puequeñas muestras con remplazo del conjunto de datos original. Podemos pensar al conjunto de datos original de entrenamiento como una bolsa con elementos adentro, y lo que hacemos es tomar  bolsitas de menor tamaño para realizar distintos árboles de decisión. Esto se hace secuencialmente, es decir: tomamos una bolsita, entrenamos un árbol de decisión con estos datos, luego reponemos la bolsita en la bolsa original y volvemos a tomar otra bolsita para generar otro árbol de decisión. Esto se repite $B$ veces y luego lo que se hace es promediar las probabilidades predichas por cada árbol en los $B$ árboles obtenidos (en el caso de regresión) o de fijarse cuál es la clase o nivel más votado (en el caso de clasificación).\n",
    "\n",
    "Random forest se diferencia del método de Bagging al incorporar además la selección de un subconjunto de las variables en cada iteración. Esto evita la correlación entre los distintos árboles de decisión. Además, permite hacer una selección de variables relevantes ya que se puede obtener una importancia relativa de cada variable en la predicción. Esta mezcla de distintos modelos estadísticos y métodos de aprendizaje automático para obtener mejor performance predictiva caracteriza a los métodos llamados de ensamble o *ensemble methods*. Estamos mezclando varios modelos con tal de aumentar la capacidad predictiva del modelo global.\n",
    "\n",
    "Como pueden ir dándose una idea, estos métodos recién pudieron ser útiles con el avance de la tecnología de las computadoras actuales. Las primeras ideas referidas a random forests fueron propuestas en 1995 y la extensión del algoritmo que se utiliza al día de hoy se patentó en 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=10, random_state=2)\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('./images/confusion_matrix.png',width=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_random_forest_tree(index):\n",
    "    assert(len(clf.estimators_) > index)\n",
    "    dot_data = tree.export_graphviz(clf.estimators_[index], out_file=None, \n",
    "                     feature_names=dataset.feature_names,  \n",
    "                     class_names=dataset.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_random_forest_tree(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(clf.feature_importances_,index=dataset.feature_names).sort_values(ascending=False)\n",
    "feature_imp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "# creamos el gráfico de barras\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# agregamos estilo\n",
    "plt.xlabel('Importancia de la variable')\n",
    "plt.ylabel('Variables')\n",
    "plt.title(\"Visualizando las variables relevantes\")\n",
    "\n",
    "#mostramos y cerramos gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo interesante de uso de Random Forests: https://www.kaggle.com/zlatankr/titanic-random-forest-82-78/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias:\n",
    " *  [Random forests and other randomized tree ensembles](https://scikit-learn.org/stable/modules/ensemble.html#forest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6b65fc4380ac725e50a330b268a227bbdbe91bddfffbf68e5f7ce9848a2b8d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
